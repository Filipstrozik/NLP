{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I część"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 zad\n",
    "Należy wykonać strojenie modelu BERT-base na danych pozyskanych w ramach\n",
    "Zadania 1. Można również wykorzystać inne dane treningowo-testowe. Proszę\n",
    "wykorzystać model polskojęzyczny (np. allegro/herbert-base-cased).\n",
    "Uwaga: proszę zastosować również adapter PEFT!!! [1,5pkt]\n",
    "1. Wykonać strojenie dla zadania klasyfikacji tekstu\n",
    "(BertForSequenceClassification)\n",
    "1. Wykonać strojenie dla zadania klasyfikacji tokenów\n",
    "(BertForTokenClassification)\n",
    "1. Wydzielić niewielki zbiór testowy i ocenić jakość predykcji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 zad\n",
    "Zwizualizować przestrzeń wektorową dla przykładów testowych (wystarczy\n",
    "jedynie klasyikacja tekstu) i zrobić interaktywny wykres przedstawiający to, w\n",
    "jaki sposób przypadki testowe organizują się w przestrzeni wektorowej\n",
    "względem przypisanych etykiet. [1pkt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W przypadku wykorzystania adaptera PEFT proszę wykorzystać reprezentacje\n",
    "tokenu [CLS] jako reprezentację tekstu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 zad\n",
    "Powtórzyć podpunkty 1 i 2 z wykorzystaniem klas GPT2ForSequenceClassification\n",
    "i GPT2ForTokenClassification. Proszę wykorzystać model polskojęzyczny (np.\n",
    "sdadas/polish-gpt2-medium) Uwaga: proszę zastosować również adapter\n",
    "PEFT!!! [1pkt]\n",
    "- W przypadku wykorzystania adaptera PEFT proszę wykorzystać reprezentacje\n",
    "ostatniego tokenu sekwencji tekstowej jako reprezentację tekstu.\n",
    "- Proszę również zamaskować tokeny paddingu i znacznik <eos> za pomocą\n",
    "etykietki -100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 zad\n",
    "Wykorzystać token [MASK] w modelu BERT do powiększenia zbiorów\n",
    "treningowych (ang. data augmentation). [0,5pkt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 zad\n",
    "Wykorzystać generatywne zdolności GPT-2 i różne hiperparametry generacji, np.\n",
    "temperatura, top-p, top-k, powiększenia zbiorów treningowych (ang. data\n",
    "augmentation). [1pkt]\n",
    "- Uwaga! W podpunktach 4 i 5 można również połączyć wykorzystanie modelu\n",
    "BERT i GPT-2 w ramach zagadnienia powiększania zbiorów danych. Wystarczy\n",
    "wytrenować jeden model na powiększonym zbiorze danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II część - Analiza własności modeli językowych (4 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 zad\n",
    "Należy wykorzystać dołączony do zadania zbiór danych z podpunktu A i\n",
    "odtworzyć badanie z podpunktu B dla modeli BERT i GPT-2 . [2pkt]\n",
    "1. wykonać analizę anizotropii (Anisotropy)\n",
    "1. wykonać analizę zależności od kontekstu (Context-Specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 zad\n",
    "Proszę wykorzystać technikę Parameter Projection omówioną w artykule z\n",
    "podpunktu C niniejszej instrukcji, następnie dokonać analizy modeli BERT-base i\n",
    "GPT-2 [1,5pkt]\n",
    "1. do analizy należy wybrać modele polskojęzyczny\n",
    "sdadas/polish-gpt2-medium,\n",
    "1. proszę utworzyć listy z załączników C.1 oraz C.2 przedstawionych w\n",
    "artykule,\n",
    "1. należy przeanalizować utworzone listy i podsumować uzyskane rezultaty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
